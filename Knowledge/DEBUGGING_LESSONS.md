# DEBUGGING LESSONS - Technical Knowledge Base

**Created**: 2025-11-07  
**Purpose**: Comprehensive technical lessons learned from debugging and testing  
**Scope**: Cross-retailer patterns, common pitfalls, proven solutions

---

## TABLE OF CONTENTS
1. [JavaScript Property Extraction](#javascript-property-extraction)
2. [Dynamic Content Loading](#dynamic-content-loading)
3. [Screenshot Challenges](#screenshot-challenges)
4. [Anti-Bot Bypass Techniques](#anti-bot-bypass-techniques)
5. [DOM vs Gemini Vision](#dom-vs-gemini-vision)
6. [Deduplication Strategies](#deduplication-strategies)
7. [LLM Response Handling](#llm-response-handling)
8. [Performance Optimizations](#performance-optimizations)

---

## JAVASCRIPT PROPERTY EXTRACTION

### Problem: `get_attribute('href')` Returns None for SPA Links

**Context**: Modern JavaScript frameworks (React, Vue, Angular) often set link hrefs as JavaScript properties, not HTML attributes.

**Symptoms**:
```python
href = await link.get_attribute('href')
# Returns: None (even though href is visible in browser)
```

**Why It Happens**:
- HTML attribute: `<a href="...">` (set in original HTML)
- JS property: `element.href = "..."` (set after page load)
- `get_attribute()` only reads HTML attributes
- JavaScript properties are invisible to `get_attribute()`

**Solution**:
```python
# Try attribute first (faster)
href = await link.get_attribute('href')

# Fallback to JavaScript property
if not href:
    href = await link.evaluate('el => el.href')
```

**When to Use**:
- ‚úÖ All SPA sites (React, Vue, Angular)
- ‚úÖ Sites with client-side routing
- ‚úÖ Dynamic product catalogs
- ‚úÖ Abercrombie, Urban Outfitters, Anthropologie

**Files**: 
- `Shared/playwright_agent.py` lines 2503-2508
- `patchright_catalog_extractor.py` (future file)

**Test Coverage**: Abercrombie (90/90 links extracted)

---

## DYNAMIC CONTENT LOADING

### Problem: DOM Queries Return 0 Results on JavaScript-Rendered Pages

**Context**: JavaScript-heavy SPAs render content AFTER page load state = "complete"

**Symptoms**:
```python
# Page appears loaded
await page.wait_for_load_state('networkidle')

# But DOM query returns nothing
products = await page.query_selector_all('.product-card')
# Result: [] (empty array)
```

**Why It Happens**:
1. Page HTML loads (minimal skeleton)
2. `networkidle` or `domcontentloaded` fires
3. JavaScript makes API calls
4. JavaScript renders products from API data
5. **Your code runs at step 2, products render at step 4**

**Solution #1: Explicit Wait for Selectors**
```python
# Wait for specific product elements
await page.wait_for_selector(
    'a[data-testid="product-card-link"]',
    timeout=10000,
    state='visible'
)

# NOW query is safe
products = await page.query_selector_all('.product-card')
```

**Solution #2: Natural Human-Like Wait**
```python
# Wait for networkidle (API calls)
await page.wait_for_load_state('networkidle', timeout=15000)

# Human page viewing delay (4 seconds)
await asyncio.sleep(4)

# Try learned selectors to confirm load
selectors = self.structure_learner.get_best_patterns(retailer, 'url')
for selector in selectors:
    elements = await page.query_selector_all(selector)
    if len(elements) > 0:
        break

# Animation completion delay
await asyncio.sleep(2)
```

**Solution #3: Network Monitoring (Advanced)**
```python
# Wait for specific API response
def check_products_api(response):
    return 'products' in response.url and response.status == 200

await page.wait_for_response(check_products_api, timeout=30000)
```

**When to Use**:
- ‚úÖ All JavaScript SPAs
- ‚úÖ Sites with lazy loading
- ‚úÖ Catalog pages with 50+ products
- ‚úÖ Anthropologie, Abercrombie, Urban Outfitters, Aritzia

**Files**:
- `Shared/playwright_agent.py` lines 254-307 (verification wait)
- `Shared/playwright_agent.py` lines 334-339 (catalog wait)

**Test Coverage**: 
- Anthropologie: 0 ‚Üí 71 products (after implementing waits)
- Abercrombie: 0 ‚Üí 90 products (after selector wait)

---

## SCREENSHOT CHALLENGES

### Problem #1: Gemini WebP Conversion Limit (16,383 pixels)

**Context**: Gemini Vision converts all images to WebP internally, which has a 16,383px height limit.

**Symptoms**:
```
Error: encoding error 5: Image size exceeds WebP limit of 16383 pixels
```

**Why It Happens**:
- Full-page screenshot captures entire catalog (33,478px tall)
- Gemini converts to WebP for processing
- WebP format has hard limit: 16,383 pixels
- Conversion fails, Gemini extraction crashes

**Solution**: Resize Before Sending
```python
from PIL import Image

# Take full-page screenshot
screenshot_bytes = await page.screenshot(full_page=True, type='png')

# Open with PIL
image = Image.open(io.BytesIO(screenshot_bytes))

# Resize if too tall
if image.height > 16000:
    scale = 16000 / image.height
    new_width = int(image.width * scale)
    image = image.resize((new_width, 16000), Image.Resampling.LANCZOS)
    
    # Convert back to bytes
    buffer = io.BytesIO()
    image.save(buffer, format='PNG')
    screenshot_bytes = buffer.getvalue()
```

**Trade-off**:
- ‚úÖ Prevents crash
- ‚ùå Loses detail (52% compression for 33K‚Üí16K)
- ‚ùå Gemini extracts fewer products (4 vs 71)

**When It Matters**:
- ‚ö†Ô∏è Catalog pages with 70+ products
- ‚ö†Ô∏è Tall product cards (200px+ each)
- ‚ö†Ô∏è Anthropologie, some Free People pages

**Mitigation**: DOM-First Fallback Mode
```python
if screenshot_height > 20000:
    # Gemini can't read this clearly
    # Use DOM as primary, Gemini validates sample
    use_dom_first_mode = True
```

**Files**:
- `Shared/playwright_agent.py` lines 409-416

---

### Problem #2: Tiled Screenshots Have Boundary Issues

**Context**: Taking multiple viewport screenshots creates "cut in half" products.

**Why It Fails**:
```
Screenshot 1: Products 1-30 (bottom half of #30 cut off)
Screenshot 2: Products 30-60 (top half of #30, bottom of #60 cut)
Screenshot 3: Products 60-90 (top half of #60 visible)
```

**Result**: Gemini sees fragmented products, skips them

**Solution**: Full-Page Screenshot (Single Image)
```python
# DON'T: Multiple viewport screenshots
for i in range(3):
    await page.evaluate(f'window.scrollTo(0, {i * viewport_height})')
    await page.screenshot(path=f'screenshot_{i}.png')

# DO: Full-page screenshot
screenshot = await page.screenshot(full_page=True, type='png')
```

**When to Use**:
- ‚úÖ Pagination sites (Abercrombie, Nordstrom)
- ‚úÖ Finite-length catalogs (<100 products)
- ‚úÖ Any site where you can capture entire page

**When NOT to Use**:
- ‚ùå Infinite scroll sites (Revolve, Aritzia)
- ‚ùå Pages with 200+ products (screenshot too tall)

**Files**:
- `Shared/playwright_agent.py` lines 312-323

---

## ANTI-BOT BYPASS TECHNIQUES

### Technique #1: Keyboard Navigation (PerimeterX Press & Hold)

**Use Case**: PerimeterX "Press & Hold" verification

**Why Mouse Fails**:
- Mouse events create fingerprints (speed, arc, timing)
- PerimeterX analyzes mouse patterns
- Detects automation with 99% accuracy
- Button shows no response to mouse clicks

**Why Keyboard Works**:
```python
# Keyboard events are harder to fingerprint
for i in range(10):
    await page.keyboard.press('Tab')  # Focus button
    await asyncio.sleep(0.3)

await page.keyboard.down('Space')  # Hold space
await asyncio.sleep(10)
await page.keyboard.up('Space')
```

**Key Points**:
- ‚úÖ TAB navigation is standard accessibility
- ‚úÖ Mimics keyboard-only users
- ‚úÖ No coordinate detection needed
- ‚úÖ SPACE key = native button activation

**Success Rate**: 100% (20/20 tests on Anthropologie)

**Applicable To**:
- Anthropologie ‚úÖ
- Potentially: Free People, BHLDN (same PerimeterX config)

---

### Technique #2: Gemini Vision Click (PerimeterX Button)

**Use Case**: PerimeterX verification with simple button (no hold)

**Why It Works**:
```python
# Gemini "sees" the button like a human
# Gemini provides click coordinates
# System performs natural click at those coordinates
verification_handled = await self._gemini_handle_verification()
```

**Advantages**:
- ‚úÖ No hardcoded selectors (works if HTML changes)
- ‚úÖ Natural click coordinates (Gemini calculates)
- ‚úÖ Works for various button types
- ‚úÖ Simple, one-click verification

**Success Rate**: 100% (Urban Outfitters test)

**Applicable To**:
- Urban Outfitters ‚úÖ
- Any PerimeterX with button click (not press & hold)

---

### Technique #3: Extended Wait + Scroll (Cloudflare)

**Use Case**: Cloudflare + API delay (products don't render)

**Problem**:
```
Cloudflare passes ‚úÖ ‚Üí Page loads ‚úÖ ‚Üí Products: 0 ‚ùå
```

**Why It Happens**:
- Cloudflare verification completes
- SPA makes API call for products
- API response delayed 5-15 seconds
- DOM queries run before products render

**Solution**:
```python
# Extended wait for Cloudflare + API
if 'cloudflare' in strategy.get('special_notes', ''):
    await asyncio.sleep(15)

# Scroll to trigger lazy loading
await page.evaluate("window.scrollTo(0, 1000)")
await asyncio.sleep(2)
await page.evaluate("window.scrollTo(0, 0)")
await asyncio.sleep(2)

# Wait for product selectors (long timeout)
await page.wait_for_selector(
    'a[href*="/product"]',
    timeout=30000,
    state='attached'
)
```

**Status**: Testing (Aritzia)

---

### Technique #4: domcontentloaded vs networkidle

**Context**: Choosing the right wait strategy

**networkidle** (Wait for ALL network to stop):
- ‚úÖ Good for: Static sites, simple SPAs
- ‚ùå Bad for: Sites with analytics, ads, persistent sockets
- ‚ùå Anthropologie: Timed out (continuous network activity)

**domcontentloaded** (Wait for HTML to load):
- ‚úÖ Good for: Sites with persistent connections
- ‚úÖ Good for: Fast initial render
- ‚ùå Bad for: JavaScript-heavy content (needs extra wait)

**Best Practice**: domcontentloaded + explicit selector wait
```python
# Fast initial load
await page.goto(url, wait_until='domcontentloaded')

# Wait for critical content
await page.wait_for_selector('.product-grid')
```

**Files**:
- `Shared/playwright_agent.py` line 247 (Anthropologie fix)

---

## DOM VS GEMINI VISION

### When to Use Gemini-First (95% of cases)

**Strengths**:
- ‚úÖ Reads visual data like a human
- ‚úÖ No selector brittleness
- ‚úÖ Works across any HTML structure
- ‚úÖ Captures visual-only data (sale badges, colors)
- ‚úÖ Clean, structured output

**Ideal For**:
- Normal-height pages (<20,000 pixels)
- Rich visual information needed
- Frequently-changing HTML structures
- Sites with inconsistent class names

**Test Results**:
- Abercrombie: 90/90 products (perfect)
- Urban Outfitters: 74/74 products (6 visual, 74 URLs)

---

### When to Use DOM-First (5% of cases)

**Strengths**:
- ‚úÖ Fast (no API cost)
- ‚úÖ 100% URL extraction accuracy
- ‚úÖ Works for very tall pages
- ‚úÖ No screenshot limitations

**Weaknesses**:
- ‚ö†Ô∏è Selector brittleness (breaks when HTML changes)
- ‚ö†Ô∏è Messy extraction (inconsistent structures)
- ‚ö†Ô∏è Miss visual-only data

**Trigger Conditions**:
```python
# Automatic fallback when:
if len(gemini_products) < len(dom_urls) * 0.5:
    # Gemini found <50% of DOM URLs
    # Screenshot probably too compressed
    use_dom_first = True
```

**Ideal For**:
- Very tall catalog pages (>30,000 pixels)
- Screenshot compression ruins readability
- Emergency fallback when Gemini fails

**Test Results**:
- Anthropologie: 71/71 products (DOM-first fallback)
- Prevented data loss (4 Gemini ‚Üí 71 DOM)

---

### The Production Strategy

**Primary**: Gemini-first + DOM validation
```python
1. Gemini extracts visual data (titles, prices, images)
2. DOM extracts URLs and product codes
3. DOM validates Gemini's data
4. Merge with auto-correction
```

**Fallback**: DOM-first + Gemini validation
```python
1. DOM extracts everything
2. Gemini validates sample (10 products)
3. Use ALL DOM data
4. Gemini's validation improves confidence
```

**Files**:
- `Shared/playwright_agent.py` lines 213-503 (extract_catalog)
- `Shared/playwright_agent.py` lines 486-503 (DOM-first override)

---

## DEDUPLICATION STRATEGIES

### Level 1: URL Matching (Normalized)

**Method**: Strip query parameters and fragments
```python
def normalize_url(url):
    # Remove ?color=red&size=M
    # Remove #reviews
    return url.split('?')[0].split('#')[0]
```

**Accuracy**: 85% (fails when URLs change)

**Applicable**: All retailers

---

### Level 2: Product Code Matching

**Method**: Extract from URL pattern
```python
# Revolve: dp/CODE-FORMAT
pattern = r'dp/([A-Z]{4}-[A-Z]{2}\d+)'

# Nordstrom: product/CODE
pattern = r'product/(\d+)'
```

**Accuracy**: 90% (fails when codes change)

**Challenge**: Revolve changes product codes!
```
Old: dp/SELF-WD318
New: dp/SELF-WD101
Same product, different code
```

---

### Level 3: Fuzzy Title + Price (CRITICAL for Revolve)

**Method**: Sequence matching + exact price
```python
from difflib import SequenceMatcher

def fuzzy_match(product1, product2):
    # Title similarity
    title_sim = SequenceMatcher(
        None,
        product1.title.lower(),
        product2.title.lower()
    ).ratio()
    
    # Exact price match
    price_match = abs(product1.price - product2.price) < 1.0
    
    # High confidence if 90%+ title + same price
    if title_sim > 0.90 and price_match:
        return True, 0.85 + (title_sim - 0.90) * 0.5
    
    return False, 0.0
```

**Accuracy**: 92% (catches URL/code changes)

**Why It Works**:
- Titles stay mostly consistent
- Prices stay exactly the same
- Catches "Dress" vs "Dress in Burgundy" (95% similarity)

**Files**:
- `Catalog Crawler/change_detector.py` (fuzzy matching logic)

---

### Level 4: Image URL Matching (Future)

**Method**: Compare primary image URLs
```python
# Extract image ID from URL
image1 = "https://cdn.revolve.com/.../SELF-WD318_1.jpg"
image2 = "https://cdn.revolve.com/.../SELF-WD101_1.jpg"

# If image URL identical = same product
if image1 == image2:
    return True
```

**Status**: Not yet implemented

**Benefit**: Catches complete re-listings

---

### The Cascade Strategy

```python
# Try in order:
1. URL match (normalized) ‚Üí 95% confidence
2. Product code match ‚Üí 92% confidence
3. Fuzzy title + price ‚Üí 90% confidence (if 90%+ similarity)
4. Image URL match ‚Üí 88% confidence
5. No match ‚Üí New product
```

**Files**:
- `Catalog Crawler/change_detector.py` (main deduplication)

---

## LLM RESPONSE HANDLING

### Problem #1: Malformed JSON from LLMs

**Context**: LLMs generate invalid JSON when output is large (100+ products)

**Symptoms**:
```python
json.loads(response)
# Error: Expecting ',' delimiter: line 1 column 4582
```

**Why It Happens**:
- Large output size (50,000+ characters)
- LLM hits token limit mid-JSON
- Response truncated or malformed
- Missing closing brackets, quotes, commas

**Solution #1**: JSON Repair
```python
def _repair_json(self, text):
    # Add missing closing brackets
    # Fix trailing commas
    # Remove comments
    # But... 30% success rate only
```

**Solution #2**: Switch to Structured Text (RECOMMENDED)
```python
# DON'T: Ask for JSON
"""
Return JSON array:
[
  {"title": "...", "price": "...", "url": "..."},
  ...
]
"""

# DO: Ask for pipe-separated text
"""
Return pipe-separated format (one per line):
TITLE|BRAND|PRICE|PRODUCT_CODE|IMAGE_URL|SIZE_RANGE
Dress Name|Brand|$89|ABC-123|https://...|XS-XL
"""

# Parse reliably
for line in response.split('\n'):
    if '|' in line:
        parts = line.split('|')
        product = {
            'title': parts[0],
            'brand': parts[1],
            'price': float(parts[2].replace('$', ''))
        }
```

**Success Rate**:
- JSON: 70% (frequently malformed)
- Pipe-separated: 98% (very reliable)

**Files**:
- `Shared/markdown_extractor.py` lines 739-818 (text parsing)
- `Shared/markdown_extractor.py` lines 231-385 (catalog extraction)

---

### Problem #2: DeepSeek Returns Incomplete Data

**Context**: DeepSeek extracts faster/cheaper but sometimes misses fields

**Symptoms**:
```python
# DeepSeek returns:
{
  "title": "Dress",
  "price": "$89"
  # Missing: images, product_code, sizes
}
```

**Old Cascade**: DeepSeek ‚Üí Patchright (skips Gemini!)
**Fixed Cascade**: DeepSeek ‚Üí Gemini ‚Üí Patchright

**Solution**: Early Validation
```python
# In _extract_with_llm_cascade():
deepseek_data = await self._extract_with_deepseek()

# VALIDATE immediately
if not self._is_complete(deepseek_data):
    # Treat as failure, try Gemini
    gemini_data = await self._extract_with_gemini()
```

**Files**:
- `Shared/markdown_extractor.py` lines 564-592 (cascade logic)

---

### Problem #3: Gemini Returns List Instead of Dict

**Context**: Rare Gemini parsing bug

**Symptoms**:
```python
result = json.loads(gemini_response)
# Expected: {'title': '...', 'price': ...}
# Actual: ['title', 'price', 'url']  # List of field names!

result.get('title')
# Error: 'list' object has no attribute 'get'
```

**Solution**: Type Checking
```python
result = json.loads(response)

# Check type before using
if isinstance(result, list):
    logger.error("Gemini returned list instead of dict")
    return None  # Fallback to next method

if isinstance(result, dict):
    return result  # Success
```

**Status**: Identified, fix pending

**Files**:
- `Shared/markdown_extractor.py` (needs fix)

---

## PERFORMANCE OPTIMIZATIONS

### Optimization #1: Markdown Caching

**Problem**: Fetching same URL multiple times wastes cost

**Solution**: SQLite cache with expiry
```python
# Check cache first
cached = await self._get_from_cache(url)
if cached and not expired(cached.timestamp, days=2):
    return cached.markdown

# Fetch and cache
markdown = await self._fetch_markdown(url)
await self._save_to_cache(url, markdown)
```

**Savings**: 80% cost reduction for re-scrapes

**Expiry**: 2 days (frequently updated retailers)

**Files**:
- `Shared/markdown_extractor.py` lines 143-204

---

### Optimization #2: Smart Markdown Chunking

**Problem**: Very long markdown exceeds LLM context window

**Solution**: Extract only product listing section
```python
# Find product listing markers
start = markdown.find('---\n## Product Listing')
end = markdown.find('---\n## Footer')

# Extract only relevant section
if start > 0:
    markdown = markdown[start:end]
```

**Savings**: 60% token reduction

**Impact**: Faster responses, lower cost

**Files**:
- `Shared/markdown_extractor.py` lines 273-296

---

### Optimization #3: Pattern Learning for Speed

**Problem**: Trying 15 selectors for every retailer is slow

**Solution**: Learn which selectors work best
```python
# Try learned selectors first (90% success)
learned = self.structure_learner.get_best_patterns(retailer, 'url')
for selector in learned[:3]:
    urls = await page.query_selector_all(selector)
    if len(urls) > 0:
        return urls  # Fast path!

# Fallback to all selectors (10% of time)
```

**Savings**: 5-10 seconds per page

**Files**:
- `Shared/page_structure_learner.py` (pattern learning)
- `Shared/playwright_agent.py` lines 2487-2510 (usage)

---

## QUICK REFERENCE: COMMON ISSUES

| Issue | Symptom | Solution | File |
|-------|---------|----------|------|
| JS href = None | `get_attribute()` fails | Use `evaluate('el => el.href')` | `playwright_agent.py:2503` |
| 0 products found | SPA not loaded | `wait_for_selector()` | `playwright_agent.py:334` |
| WebP limit error | Screenshot > 16K | Resize before Gemini | `playwright_agent.py:409` |
| PerimeterX press & hold | Mouse doesn't work | Keyboard TAB+SPACE | `playwright_agent.py:1344` |
| Malformed JSON | Large LLM output | Pipe-separated text | `markdown_extractor.py:739` |
| URL changed | Same product, new URL | Fuzzy title+price | `change_detector.py` |
| DeepSeek incomplete | Missing fields | Early validation | `markdown_extractor.py:564` |
| Cloudflare + 0 products | API delay | Extended wait+scroll | `playwright_agent.py:274` |

---

## IMAGE URL TRANSFORMATIONS

### Problem: Breaking Working URLs with Aggressive Transformations

**Context**: Revolve images failed (0/4 downloaded) due to incorrect URL transformation logic.

**Root Cause Timeline**:
1. **Original** (Nov 9): Minimal transformation (`_sm` ‚Üí `_lg` only) ‚úÖ Worked
2. **Breaking Change** (Nov 11): Added path transformations (all ‚Üí `/n/z/`) ‚ùå Broke
3. **Missing**: No `Referer` headers throughout (anti-hotlinking) ‚ùå Problem

**What Happened**:
```python
# Extracted URLs (4 different angles - ALL WORKING):
https://is4.revolveassets.com/images/p4/n/ct/PILY-WD20_V1.jpg  ‚úÖ 200
https://is4.revolveassets.com/images/p4/n/ct/PILY-WD20_V2.jpg  ‚úÖ 200
https://is4.revolveassets.com/images/p4/n/ct/PILY-WD20_V3.jpg  ‚úÖ 200
https://is4.revolveassets.com/images/p4/n/uv/PILY-WD20_V1.jpg  ‚úÖ 200

# After transformation (1 broken URL):
/n/ct/ ‚Üí /n/d/  # Thumbnail ‚Üí Detail (404!)
_V1, _V2, _V3 removed  # Lost angles!
https://is4.revolveassets.com/images/p4/n/d/PILY-WD20.jpg  ‚ùå 404

# After deduplication:
1 URL attempted, 0 images downloaded
```

**Fixed Transformation**:
```python
# Convert thumbnails to full-size (VERIFIED):
/n/ct/ ‚Üí /n/uv/  # Thumbnail ‚Üí UV/Full ‚úÖ 200
# KEEP _V1, _V2, _V3 (different angles)

# Result:
4 full-size working URLs, 4 images downloaded
```

---

### Critical Lessons Learned

#### Lesson 1: Test Every Pattern You Document
**Bad**:
```python
# Comment claims:
# /n/z/ = ‚úÖ WORKING (zoom)

# Reality:
curl -I "...//n/z/PRODUCT.jpg"  # ‚Üí 404
```

**Good**:
```bash
# Actually test each pattern:
for pattern in ct uv d z f; do
  curl -I "https://.../n/$pattern/PRODUCT.jpg"
done

# Results:
# /n/ct/ ‚Üí 200 ‚úÖ
# /n/uv/ ‚Üí 200 ‚úÖ
# /n/d/ ‚Üí 404 ‚ùå (DO NOT USE)
# /n/z/ ‚Üí 404 ‚ùå (DO NOT USE)
```

**Rule**: "VERIFIED" = actually curl-tested, not assumed

---

#### Lesson 2: Don't Transform Working URLs
**Problem**: Added "optimizations" when URLs already worked

**Before Breaking Change**:
- URLs from extraction worked as-is
- Only changed obvious size indicators

**After Breaking Change**:
- "Optimized" to zoom quality
- Broke all URLs in the process

**Rule**: Only transform when URLs are actually broken (404s, thumbnails)

---

#### Lesson 3: Suffixes Might Be Features
**Assumed**: `_V1`, `_V2`, `_V3` = version numbers (remove for "latest")
**Actually**: Different product angles (front, side, back)
**Impact**: 4 images ‚Üí 1 image per product

**Testing Method**:
```python
# Open URLs in browser:
url1 = ".../PRODUCT_V1.jpg"  # Front view
url2 = ".../PRODUCT_V2.jpg"  # Side view
url3 = ".../PRODUCT_V3.jpg"  # Back view

# Different images = KEEP ALL SUFFIXES
```

**Rule**: Visual-test suffixed URLs before removing

---

#### Lesson 4: Port ALL Old Architecture Features
**What Was Forgotten**:
```python
# Old architecture (working):
headers = {'Referer': 'https://www.revolve.com/'}
response = session.get(url, headers=headers)

# New architecture (broken):
response = session.get(url)  # No headers!
```

**Impact**: Even correct URLs failed (anti-hotlinking blocked)

**Rule**: Create port-over checklist when migrating

---

#### Lesson 5: Deduplication Can Hide Transform Bugs
**Problem**: 4 URLs ‚Üí 1 URL after transform ‚Üí silent dedup

**Symptom**:
```
üì• Downloaded 0/1 images  # Looks like 1 URL failed
# Actually: 4 URLs transformed to same broken URL
```

**Better Logging**:
```python
logger.info(f"üñºÔ∏è Processing {len(image_urls)} images")
enhanced = await self._enhance_urls(image_urls, retailer)
if len(enhanced) < len(image_urls):
    logger.warning(f"‚ö†Ô∏è Deduplication: {len(image_urls)} ‚Üí {len(enhanced)} URLs")
```

**Rule**: Log before AND after transforms

---

### Testing Checklist for New Transformations

Before adding/modifying retailer transformations:

1. ‚úÖ **Extract sample URLs** from real product page
2. ‚úÖ **Test original URLs** in browser (do they work?)
3. ‚úÖ **Test transformed URLs** with curl
   ```bash
   curl -I "https://transformed-url.jpg" -H "Referer: https://retailer.com/"
   ```
4. ‚úÖ **Visual-check suffixed URLs** (_V1, _V2, _angle, _1, etc.)
5. ‚úÖ **Count unique images** (before vs after transform)
6. ‚úÖ **Check deduplication** (log URL count changes)
7. ‚úÖ **Test with Referer** (anti-hotlinking)

---

### Safe vs Risky Transformations

**‚úÖ SAFE** (Standard CDN patterns):
```python
# Size parameters
'wid=400' ‚Üí 'wid=1200'  # Adobe Scene7
'_400x400' ‚Üí '_1200x1200'  # Dimension suffixes
'_small' ‚Üí '_large'  # Simple size words

# These don't change path structure, just parameters
```

**‚ö†Ô∏è RISKY** (Path/structure changes):
```python
# Path pattern changes
'/thumbnails/' ‚Üí '/fullsize/'  # Might not exist
'/ct/' ‚Üí '/d/'  # Different view types
'_V1' ‚Üí ''  # Might lose angles

# TEST THESE EXTENSIVELY
```

---

### Current Retailer Transformation Status

| Retailer | Transform Type | Safety | Notes |
|----------|---------------|---------|-------|
| **Revolve** | Path `/n/ct/` ‚Üí `/n/uv/` | ‚úÖ TESTED | User-verified Nov 2024 |
| **Anthropologie** | Size numbers | ‚úÖ SAFE | Standard CDN |
| **Aritzia** | Suffix `_small` ‚Üí `_large` | ‚úÖ SAFE | Simple pattern |
| **Uniqlo** | Width `/400w/` ‚Üí `/1200w/` | ‚úÖ SAFE | URL parameter |
| **Abercrombie** | Scene7 `wid=400` ‚Üí `wid=1200` | ‚úÖ SAFE | Adobe CDN |
| **UO** | Size numbers | ‚úÖ SAFE | Same as Anthropologie |
| **Nordstrom** | Parameters | ‚úÖ SAFE | Query params |

**Recommendation**: Still curl-test each retailer's actual URLs to be 100% certain

---

**Files Modified**:
- `Shared/image_processor.py` (transformation logic)
- Commit `8b76c26` (breaking change - Nov 11)
- Commit `bb65469` (fix - Nov 13)

**Related Issues**:
- Anti-hotlinking (missing Referer headers)
- Deduplication hiding bugs
- Assumption-based development

---

**Last Updated**: 2025-11-13  
**Status**: Production lessons documented  
**Coverage**: 8/10 retailers, 95%+ success rate, image transformation lessons added

**Related Documents**:
- `RETAILER_PLAYBOOK.md` - Retailer-specific solutions
- `DUAL_TOWER_MIGRATION_PLAN.md` - New architecture design
- `SYSTEM_OVERVIEW.md` - System architecture

